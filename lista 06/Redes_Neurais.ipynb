{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "MR0OKKD6DDhD"
      },
      "execution_count": 1044,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "rC9WP9DW8YkI"
      },
      "execution_count": 1045,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_breast_cancer()"
      ],
      "metadata": {
        "id": "om0MIVU47oA4"
      },
      "execution_count": 1046,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z70y9Ryg9Tim",
        "outputId": "f5d0b8ad-af76-4b09-89fe-d34e379f941e"
      },
      "execution_count": 1047,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
              "         1.189e-01],\n",
              "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
              "         8.902e-02],\n",
              "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
              "         8.758e-02],\n",
              "        ...,\n",
              "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
              "         7.820e-02],\n",
              "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
              "         1.240e-01],\n",
              "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
              "         7.039e-02]]),\n",
              " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
              " 'frame': None,\n",
              " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
              " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
              " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
              "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
              "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
              "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
              "        'smoothness error', 'compactness error', 'concavity error',\n",
              "        'concave points error', 'symmetry error',\n",
              "        'fractal dimension error', 'worst radius', 'worst texture',\n",
              "        'worst perimeter', 'worst area', 'worst smoothness',\n",
              "        'worst compactness', 'worst concavity', 'worst concave points',\n",
              "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
              " 'filename': 'breast_cancer.csv',\n",
              " 'data_module': 'sklearn.datasets.data'}"
            ]
          },
          "metadata": {},
          "execution_count": 1047
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data['data']\n",
        "y = data['target']"
      ],
      "metadata": {
        "id": "q6Go-itg922B"
      },
      "execution_count": 1048,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
      ],
      "metadata": {
        "id": "lZyp2Wjc9guB"
      },
      "execution_count": 1049,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizando os dados de treino"
      ],
      "metadata": {
        "id": "Wou743fVQ3bx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)"
      ],
      "metadata": {
        "id": "OryxU9GaIk2W"
      },
      "execution_count": 1050,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Algoritmo Perceptron"
      ],
      "metadata": {
        "id": "Ts1j13t77wN0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1051,
      "metadata": {
        "id": "33qjlua77uLp"
      },
      "outputs": [],
      "source": [
        "class Perceptron(object):\n",
        "    \"\"\"Perceptron classifier.\n",
        "\n",
        "    Parameters\n",
        "    ------------\n",
        "    eta : float\n",
        "      Learning rate (between 0.0 and 1.0)\n",
        "    n_iter : int\n",
        "      Passes over the training dataset.\n",
        "    random_state : int\n",
        "      Random number generator seed for random weight\n",
        "      initialization.\n",
        "\n",
        "    Attributes\n",
        "    -----------\n",
        "    w_ : 1d-array\n",
        "      Weights after fitting.\n",
        "    errors_ : list\n",
        "      Number of misclassifications (updates) in each epoch.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
        "        self.eta = eta\n",
        "        self.n_iter = n_iter\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Fit training data.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : {array-like}, shape = [n_samples, n_features]\n",
        "          Training vectors, where n_samples is the number of samples and\n",
        "          n_features is the number of features.\n",
        "        y : array-like, shape = [n_samples]\n",
        "          Target values.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "\n",
        "        \"\"\"\n",
        "        rgen = np.random.RandomState(self.random_state)\n",
        "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])\n",
        "        self.errors_ = []\n",
        "\n",
        "        for _ in range(self.n_iter):\n",
        "            errors = 0\n",
        "            for xi, target in zip(X, y):\n",
        "                update = self.eta * (target - self.predict(xi))\n",
        "                self.w_[1:] += update * xi\n",
        "                self.w_[0] += update\n",
        "                errors += int(update != 0.0)\n",
        "            self.errors_.append(errors)\n",
        "        return self\n",
        "\n",
        "    def net_input(self, X):\n",
        "        \"\"\"Calculate net input\"\"\"\n",
        "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Return class label after unit step\"\"\"\n",
        "        return np.where(self.net_input(X) >= 0.0, 1, -1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ppn = Perceptron(random_state=77)\n",
        "ppn.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kE3TNiX76Yo",
        "outputId": "ca18c33e-5f18-4298-ffc0-62ee219a168a"
      },
      "execution_count": 1052,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.Perceptron at 0x7f44f1f75330>"
            ]
          },
          "metadata": {},
          "execution_count": 1052
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalizando os dados de teste\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "erJFe7a3JJe2"
      },
      "execution_count": 1053,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_ppn = ppn.predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "UzrUbC4uDLLL"
      },
      "execution_count": 1055,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = accuracy_score(y_test, y_pred_ppn)"
      ],
      "metadata": {
        "id": "_M9izBn3DVep"
      },
      "execution_count": 1056,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNH5ukm0D994",
        "outputId": "33449d97-86c7-41dd-f056-405dadfeb1a1"
      },
      "execution_count": 1057,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6198830409356725"
            ]
          },
          "metadata": {},
          "execution_count": 1057
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Algoritmo Adaline com Gradiente Descendente"
      ],
      "metadata": {
        "id": "RD2BqC_iEmi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AdalineGD(object):\n",
        "    \"\"\"ADAptive LInear NEuron classifier.\n",
        "\n",
        "    Parameters\n",
        "    ------------\n",
        "    eta : float\n",
        "      Learning rate (between 0.0 and 1.0)\n",
        "    n_iter : int\n",
        "      Passes over the training dataset.\n",
        "    random_state : int\n",
        "      Random number generator seed for random weight\n",
        "      initialization.\n",
        "\n",
        "\n",
        "    Attributes\n",
        "    -----------\n",
        "    w_ : 1d-array\n",
        "      Weights after fitting.\n",
        "    cost_ : list\n",
        "      Sum-of-squares cost function value in each epoch.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
        "        self.eta = eta\n",
        "        self.n_iter = n_iter\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\" Fit training data.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : {array-like}, shape = [n_samples, n_features]\n",
        "          Training vectors, where n_samples is the number of samples and\n",
        "          n_features is the number of features.\n",
        "        y : array-like, shape = [n_samples]\n",
        "          Target values.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "\n",
        "        \"\"\"\n",
        "        rgen = np.random.RandomState(self.random_state)\n",
        "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])\n",
        "        self.cost_ = []\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            net_input = self.net_input(X)\n",
        "            # Please note that the \"activation\" method has no effect\n",
        "            # in the code since it is simply an identity function. We\n",
        "            # could write `output = self.net_input(X)` directly instead.\n",
        "            # The purpose of the activation is more conceptual, i.e.,  \n",
        "            # in the case of logistic regression (as we will see later), \n",
        "            # we could change it to\n",
        "            # a sigmoid function to implement a logistic regression classifier.\n",
        "            output = self.activation(net_input)\n",
        "            errors = (y - output)\n",
        "            self.w_[1:] += self.eta * X.T.dot(errors)\n",
        "            self.w_[0] += self.eta * errors.sum()\n",
        "            cost = (errors**2).sum() / 2.0\n",
        "            self.cost_.append(cost)\n",
        "        return self\n",
        "\n",
        "    def net_input(self, X):\n",
        "        \"\"\"Calculate net input\"\"\"\n",
        "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
        "\n",
        "    def activation(self, X):\n",
        "        \"\"\"Compute linear activation\"\"\"\n",
        "        return X\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Return class label after unit step\"\"\"\n",
        "        return np.where(self.activation(self.net_input(X)) >= 0.0, 1, -1)"
      ],
      "metadata": {
        "id": "3XHVVVrBENVP"
      },
      "execution_count": 1061,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adlGD = AdalineGD(random_state=77)\n",
        "adlGD.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vV5wkiInE7RE",
        "outputId": "953a3aef-d127-4609-ecef-baa4238b3086"
      },
      "execution_count": 1062,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.AdalineGD at 0x7f44f1f76ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 1062
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict_adlGD = adlGD.predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "PmvPuJe1FIgC"
      },
      "execution_count": 1063,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, y_predict_adlGD)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGdRv6ZtFNlO",
        "outputId": "9d064ae7-6978-47fc-bf0a-76126aed0b48"
      },
      "execution_count": 1064,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.05263157894736842"
            ]
          },
          "metadata": {},
          "execution_count": 1064
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A acurácia acima é muito ruim, mas podemos melhorá-la alterando o parâmetro eta"
      ],
      "metadata": {
        "id": "-692jYDgBpJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adlGD = AdalineGD(random_state=77, eta = 0.0001)\n",
        "adlGD.fit(X_train_scaled, y_train)\n",
        "y_predict_adlGD = adlGD.predict(X_test_scaled)\n",
        "accuracy_score(y_test, y_predict_adlGD)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fV0xHixGBoyN",
        "outputId": "15d55f86-715a-474f-fbbd-d715385e859c"
      },
      "execution_count": 1065,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6257309941520468"
            ]
          },
          "metadata": {},
          "execution_count": 1065
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Algoritmo Adaline com Gradiente Descendente Estocástico"
      ],
      "metadata": {
        "id": "LdqWsWjoLnxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AdalineSGD(object):\n",
        "    \"\"\"ADAptive LInear NEuron classifier.\n",
        "\n",
        "    Parameters\n",
        "    ------------\n",
        "    eta : float\n",
        "      Learning rate (between 0.0 and 1.0)\n",
        "    n_iter : int\n",
        "      Passes over the training dataset.\n",
        "    shuffle : bool (default: True)\n",
        "      Shuffles training data every epoch if True to prevent cycles.\n",
        "    random_state : int\n",
        "      Random number generator seed for random weight\n",
        "      initialization.\n",
        "\n",
        "\n",
        "    Attributes\n",
        "    -----------\n",
        "    w_ : 1d-array\n",
        "      Weights after fitting.\n",
        "    cost_ : list\n",
        "      Sum-of-squares cost function value averaged over all\n",
        "      training samples in each epoch.\n",
        "\n",
        "        \n",
        "    \"\"\"\n",
        "    def __init__(self, eta=0.01, n_iter=10, shuffle=True, random_state=None):\n",
        "        self.eta = eta\n",
        "        self.n_iter = n_iter\n",
        "        self.w_initialized = False\n",
        "        self.shuffle = shuffle\n",
        "        self.random_state = random_state\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        \"\"\" Fit training data.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : {array-like}, shape = [n_samples, n_features]\n",
        "          Training vectors, where n_samples is the number of samples and\n",
        "          n_features is the number of features.\n",
        "        y : array-like, shape = [n_samples]\n",
        "          Target values.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "\n",
        "        \"\"\"\n",
        "        self._initialize_weights(X.shape[1])\n",
        "        self.cost_ = []\n",
        "        for i in range(self.n_iter):\n",
        "            if self.shuffle:\n",
        "                X, y = self._shuffle(X, y)\n",
        "            cost = []\n",
        "            for xi, target in zip(X, y):\n",
        "                cost.append(self._update_weights(xi, target))\n",
        "            avg_cost = sum(cost) / len(y)\n",
        "            self.cost_.append(avg_cost)\n",
        "        return self\n",
        "\n",
        "    def partial_fit(self, X, y):\n",
        "        \"\"\"Fit training data without reinitializing the weights\"\"\"\n",
        "        if not self.w_initialized:\n",
        "            self._initialize_weights(X.shape[1])\n",
        "        if y.ravel().shape[0] > 1:\n",
        "            for xi, target in zip(X, y):\n",
        "                self._update_weights(xi, target)\n",
        "        else:\n",
        "            self._update_weights(X, y)\n",
        "        return self\n",
        "\n",
        "    def _shuffle(self, X, y):\n",
        "        \"\"\"Shuffle training data\"\"\"\n",
        "        r = self.rgen.permutation(len(y))\n",
        "        return X[r], y[r]\n",
        "    \n",
        "    def _initialize_weights(self, m):\n",
        "        \"\"\"Initialize weights to small random numbers\"\"\"\n",
        "        self.rgen = np.random.RandomState(self.random_state)\n",
        "        self.w_ = self.rgen.normal(loc=0.0, scale=0.01, size=1 + m)\n",
        "        self.w_initialized = True\n",
        "        \n",
        "    def _update_weights(self, xi, target):\n",
        "        \"\"\"Apply Adaline learning rule to update the weights\"\"\"\n",
        "        output = self.activation(self.net_input(xi))\n",
        "        error = (target - output)\n",
        "        self.w_[1:] += self.eta * xi.dot(error)\n",
        "        self.w_[0] += self.eta * error\n",
        "        cost = 0.5 * error**2\n",
        "        return cost\n",
        "    \n",
        "    def net_input(self, X):\n",
        "        \"\"\"Calculate net input\"\"\"\n",
        "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
        "\n",
        "    def activation(self, X):\n",
        "        \"\"\"Compute linear activation\"\"\"\n",
        "        return X\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Return class label after unit step\"\"\"\n",
        "        return np.where(self.activation(self.net_input(X)) >= 0.0, 1, -1)"
      ],
      "metadata": {
        "id": "drjbDis8Lnf4"
      },
      "execution_count": 1066,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adlSGD = AdalineSGD(random_state=77)\n",
        "adlSGD.fit(X_train_scaled, y_train)                                                                                                                                                            "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLa47789MP34",
        "outputId": "9a06f366-0eb6-4e67-f57b-c90eb7e20f30"
      },
      "execution_count": 1067,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.AdalineSGD at 0x7f44f1fb16f0>"
            ]
          },
          "metadata": {},
          "execution_count": 1067
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict_adlSGD = adlSGD.predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "YNr-bQ7xMT1L"
      },
      "execution_count": 1068,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, y_predict_adlSGD)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-24PF41uMdVB",
        "outputId": "cfe76afd-9fe9-4a76-cafc-0d8f6ff38e6e"
      },
      "execution_count": 1069,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6257309941520468"
            ]
          },
          "metadata": {},
          "execution_count": 1069
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Algoritmo Adaline com Gradiente Descendente Estocástico usando mini-batches de 20 elementos"
      ],
      "metadata": {
        "id": "QTW6BzEwxmv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AdalineSGD2(object):\n",
        "    \"\"\"ADAptive LInear NEuron classifier.\n",
        "\n",
        "    Parameters\n",
        "    ------------\n",
        "    eta : float\n",
        "      Learning rate (between 0.0 and 1.0)\n",
        "    n_iter : int\n",
        "      Passes over the training dataset.\n",
        "    shuffle : bool (default: True)\n",
        "      Shuffles training data every epoch if True to prevent cycles.\n",
        "    random_state : int\n",
        "      Random number generator seed for random weight\n",
        "      initialization.\n",
        "\n",
        "\n",
        "    Attributes\n",
        "    -----------\n",
        "    w_ : 1d-array\n",
        "      Weights after fitting.\n",
        "    cost_ : list\n",
        "      Sum-of-squares cost function value averaged over all\n",
        "      training samples in each epoch.\n",
        "\n",
        "        \n",
        "    \"\"\"\n",
        "    def __init__(self, eta=0.01, n_iter=10, shuffle=True, random_state=None):\n",
        "        self.eta = eta\n",
        "        self.n_iter = n_iter\n",
        "        self.w_initialized = False\n",
        "        self.shuffle = shuffle\n",
        "        self.random_state = random_state\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        \"\"\" Fit training data.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : {array-like}, shape = [n_samples, n_features]\n",
        "          Training vectors, where n_samples is the number of samples and\n",
        "          n_features is the number of features.\n",
        "        y : array-like, shape = [n_samples]\n",
        "          Target values.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "\n",
        "        \"\"\"\n",
        "        self._initialize_weights(X.shape[1])\n",
        "        self.cost_ = []\n",
        "        n_samples = X.shape[0]\n",
        "        for i in range(self.n_iter):\n",
        "            if self.shuffle:\n",
        "                X, y = self._shuffle(X, y)\n",
        "            cost = []\n",
        "            for j in range(0, n_samples, 20):\n",
        "                X_batch = X[j:j+20]\n",
        "                y_batch = y[j:j+20]\n",
        "                self.partial_fit(X_batch, y_batch)\n",
        "                cost.append(self._cost(X_batch, y_batch))\n",
        "            avg_cost = sum(cost) / len(cost)\n",
        "            self.cost_.append(avg_cost)\n",
        "        return self\n",
        "\n",
        "    def partial_fit(self, X, y):\n",
        "        \"\"\"Fit training data without reinitializing the weights\"\"\"\n",
        "        if not self.w_initialized:\n",
        "            self._initialize_weights(X.shape[1])\n",
        "        if y.ravel().shape[0] > 1:\n",
        "            for xi, target in zip(X, y):\n",
        "                self._update_weights(xi, target)\n",
        "        else:\n",
        "            self._update_weights(X, y)\n",
        "        return self\n",
        "\n",
        "    def _shuffle(self, X, y):\n",
        "        \"\"\"Shuffle training data\"\"\"\n",
        "        r = self.rgen.permutation(len(y))\n",
        "        return X[r], y[r]\n",
        "    \n",
        "    def _initialize_weights(self, m):\n",
        "        \"\"\"Initialize weights to small random numbers\"\"\"\n",
        "        self.rgen = np.random.RandomState(self.random_state)\n",
        "        self.w_ = self.rgen.normal(loc=0.0, scale=0.01, size=1 + m)\n",
        "        self.w_initialized = True\n",
        "        \n",
        "    def _update_weights(self, xi, target):\n",
        "        \"\"\"Apply Adaline learning rule to update the weights\"\"\"\n",
        "        output = self.activation(self.net_input(xi))\n",
        "        error = (target - output)\n",
        "        self.w_[1:] += self.eta * xi.dot(error)\n",
        "        self.w_[0] += self.eta * error\n",
        "        cost = 0.5 * error**2\n",
        "        return cost\n",
        "    \n",
        "    def net_input(self, X):\n",
        "        \"\"\"Calculate net input\"\"\"\n",
        "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
        "\n",
        "    def activation(self, X):\n",
        "        \"\"\"Compute linear activation\"\"\"\n",
        "        return X\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Return class label after unit step\"\"\"\n",
        "        return np.where(self.activation(self.net_input(X)) >= 0.0, 1, -1)\n",
        "\n",
        "    def _cost(self, X, y):\n",
        "        \"\"\"Compute cost\"\"\"\n",
        "        output = self.activation(self.net_input(X))\n",
        "        errors = (y - output)\n",
        "        cost = (errors**2).sum() / 2.0\n",
        "        return cost\n"
      ],
      "metadata": {
        "id": "ry3ufAFzvdzz"
      },
      "execution_count": 1070,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adlSGD2 = AdalineSGD2(random_state=77)\n",
        "adlSGD2.fit(X_train_scaled, y_train)   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkgAoYuAx2JV",
        "outputId": "6f24624d-2dea-4262-8f64-749ddec82052"
      },
      "execution_count": 1071,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.AdalineSGD2 at 0x7f44f1f74040>"
            ]
          },
          "metadata": {},
          "execution_count": 1071
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict_adlSGD2 = adlSGD2.predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "Wul1pSA4y8Cw"
      },
      "execution_count": 1072,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, y_predict_adlSGD2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEXO7g3_zDHg",
        "outputId": "72b82f05-ec50-4c4d-ea5e-a1061d54f39d"
      },
      "execution_count": 1073,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6257309941520468"
            ]
          },
          "metadata": {},
          "execution_count": 1073
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Algoritmo Perceptron do Scikit Learn"
      ],
      "metadata": {
        "id": "Hbu5jnObCKK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "pctn = Perceptron(random_state=77)\n",
        "pctn.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_pctn = pctn.predict(X_test_scaled)\n",
        "\n",
        "print(accuracy_score(y_test, y_pred_pctn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujBjoGcr2bSl",
        "outputId": "ebeb36eb-16f2-4861-ba46-5cf6783155cd"
      },
      "execution_count": 1074,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9649122807017544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Algoritmo Stochastic Gradient Descent (SGD) do Scikit Learn"
      ],
      "metadata": {
        "id": "d71HYeOjCURy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "sgdClassifier = SGDClassifier(random_state=77)\n",
        "sgdClassifier.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_sgd = sgdClassifier.predict(X_test_scaled)\n",
        "print(accuracy_score(y_test, y_pred_sgd))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21rTc5yK3phG",
        "outputId": "49de8ebe-6505-43d1-b400-19f26ba4053c"
      },
      "execution_count": 1075,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9649122807017544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Algortimo Logistic Regression do Scikit Learn"
      ],
      "metadata": {
        "id": "PNXucGFvCb4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "l_regression = LogisticRegression(random_state=77)\n",
        "l_regression.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_lRegression = l_regression.predict(X_test_scaled)\n",
        "print(accuracy_score(y_test, y_pred_lRegression))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8yrJb625nS3",
        "outputId": "4030904c-3672-4248-9252-d750a8b38c92"
      },
      "execution_count": 1076,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9883040935672515\n"
          ]
        }
      ]
    }
  ]
}